{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uttam112/sprinklr/blob/main/app_run.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation\n",
        "\n",
        "\n",
        "1.   langchain\n",
        "2.   Sentence Tranformers (Embeddings)\n",
        "3.   faiss (Vector store)\n",
        "\n"
      ],
      "metadata": {
        "id": "oFa26Co2tNky"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdp9LTsUtNky"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "id": "-Np6ogdQtNkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "SCjn6unltNkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu"
      ],
      "metadata": {
        "id": "Up9_03g7tNkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss"
      ],
      "metadata": {
        "id": "o0yI0osAtNkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Embeddings from Google Drive"
      ],
      "metadata": {
        "id": "eoWv8uNVtNkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/Embeddings/rpurified_only_Sprinklr1000_200.pkl\", \"rb\") as f:\n",
        "    db = pickle.load(f)"
      ],
      "metadata": {
        "id": "Y5eccSsktNkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "S3H_baOTtNk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Give your API Key"
      ],
      "metadata": {
        "id": "-GYIo-wftNk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "26kmIerHtNk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"{Your_OpenAI_API_Key}\""
      ],
      "metadata": {
        "id": "sXweiuHqtNk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conversation Chain"
      ],
      "metadata": {
        "id": "2HGQwltItNk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferWindowMemory"
      ],
      "metadata": {
        "id": "YlTszu00tNk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "Dr7tJV2pps4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferWindowMemory(k=3)"
      ],
      "metadata": {
        "id": "oyJIjjMGtNk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory\n",
        ")\n",
        "\n",
        "print(conversation.prompt.template)\n",
        "docs = \"\"\n",
        "print('\\n\\n')\n",
        "# conversation.prompt.template = str(\"You need to behave as Sprinklr sales agent. You are currently doing the role of Sprinklr AI Assistant. You need to engage the vistors and politely pursuade them to buy our product. \\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:\")\n",
        "print(conversation)\n",
        "print(type(conversation))"
      ],
      "metadata": {
        "id": "SF3S63WotNk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Template - Stand Alone Query"
      ],
      "metadata": {
        "id": "XWmqQBLZrW5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv = []\n",
        "convo = \"\"\n",
        "message = \"\"\n",
        "chats_his = []\n",
        "llm_primary = OpenAI(temperature=0.0)"
      ],
      "metadata": {
        "id": "wqPYMDXFIbyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def args_temp():\n",
        "  kil_template = f\"\"\"Given a snippet of previous dialogue of Sprinklr sales chatbot and an upcoming user question, convert the question into a stand-alone query. Don't change the upcoming question if it is not related to sprinklr:\n",
        "  Previous conversation:\n",
        "  <actual previous conversation with sprinklr bot here>\n",
        "  Upcoming question:\n",
        "  <actual upcoming user question here>\n",
        "  Stand-alone query:\n",
        "  <converted stand-alone question here>\n",
        "\n",
        "\n",
        "  For example:[\n",
        "  example1:\n",
        "  Previous conversation:\n",
        "  []\n",
        "  Upcoming question:Hi\n",
        "  Stand-alone query:Hi\n",
        "  // previous conversation is blank so this the start of the conversation\n",
        "  example2:\n",
        "  Previous conversation:\n",
        "  ['HumanMessage:Tell me about sprinklr modern marketing',\n",
        "  Sprinklr Bot Message:Sprinklr's modern marketing services include a content management system that enables organizations to provide the correct material to their consumers at the right time, as well as a variety of other features such as Digital Asset Management (DAM), Workflow Automation, Content Analysis, and more.\n",
        "  ]\n",
        "  Upcoming question:tell me more\n",
        "  Stand-alone query: What other features does Sprinklr's modern marketing services offer?\n",
        "\n",
        "\n",
        "  example3:\n",
        "  Previous conversation:\n",
        "  []\n",
        "  Upcoming question:what is 2+2?\n",
        "  Stand-alone query:what is 2+2?\n",
        "  // this query is not related to sprinklr so let it be unchanged.\n",
        "  example4:\n",
        "  Previous conversation:\n",
        "  ['HumanMessage:Tell me about sprinklr modern marketing',\n",
        "  Sprinklr Bot Message:Sprinklr's modern marketing services include a content management system that enables organizations to provide the correct material to their consumers at the right time, as well as a variety of other features such as Digital Asset Management (DAM), Workflow Automation, Content Analysis, and more.\n",
        "  ]\n",
        "  Upcoming question:Who is virat Kohli?\n",
        "  Stand-alone query: Who is virat Kohli?\n",
        "  // this query was not related to sprinklr so let it be unchanged.\n",
        "\n",
        "\n",
        "  example5:\n",
        "  Previous conversation:\n",
        "  ['HumanMessage:tell me about sprinklr services',\n",
        "  Sprinklr Bot Message:Sprinklr offers a range of services to help businesses manage their social media presence. These include social listening, social publishing, social advertising, social engagement, and social analytics. Our platform is designed to help businesses of all sizes and industries improve their social media strategy and drive better results. Would you like more information on any of these services?\n",
        "  ]\n",
        "  Upcoming question:what else?\n",
        "  Stand-alone query: What are some other services that Sprinklr Provides?\n",
        "  ]\n",
        "  Previous conversation:\n",
        "  [{convo}]\n",
        "  Upcoming question:{message}\n",
        "  Stand-alone query: \"\"\"\n",
        "  print(convo)\n",
        "  return kil_template\n"
      ],
      "metadata": {
        "id": "78YezNc95Ntl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gradio App"
      ],
      "metadata": {
        "id": "7RcmMBqctNk-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "2-X2XnRZtNk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "RN1FznlWtNk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# message = \"what are sprinklr services?\"\n",
        "# docs = db._similarity_search_with_relevance_scores(message,k =3)\n",
        "# context = docs[0][0].page_content + \"\\n\" + docs[1][0].page_content + \"\\n\"+ docs[2][0].page_content\n",
        "# relavance_scores = {\"doc1\":docs[0][1], \"doc2\":docs[1][1] , \"doc3\":docs[2][1]}\n",
        "# template = \"You need to behave as Sprinklr sales agent. You are currently doing the role of Sprinklr AI Assistant. You need to engage the visitors and politely pursuade them to buy our product.You must extract Sprinklr's data from the context (as the context may contain data of other orgainzations as well) to answer from the context under triple backtiks-```\" + context + \"```  \\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:\"\n",
        "# conversation.prompt.template = template\n",
        "# bot_message = conversation.predict(input=message) + \"\\n\\n\" + context + \"\\n\\n\" + str(relavance_scores)"
      ],
      "metadata": {
        "id": "NM-vo-2iSma4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(bot_message)"
      ],
      "metadata": {
        "id": "DK3RtN1xTWa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conv = []\n",
        "# message = \"hi\"\n",
        "# llm_primary = OpenAI(temperature=0.0)"
      ],
      "metadata": {
        "id": "62wUR41biRGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# message = \"what do you provide?\"\n",
        "# convo = \"\"\n",
        "# kil_template = args_temp()\n",
        "# stand_alone_query = llm_primary.predict(kil_template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DaubKffjwZ1",
        "outputId": "96e0b3ff-213c-4799-b2c2-103e754b4c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(stand_alone_query)"
      ],
      "metadata": {
        "id": "zr3cYKC-kFTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import random\n",
        "import time\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "    def respond(message, chat_history):\n",
        "\n",
        "\n",
        "\n",
        "        convo = str(conv)\n",
        "        kil_template = args_temp()\n",
        "        stand_alone_query = llm_primary.predict(kil_template)\n",
        "        \"\"\"\n",
        "        Will make a stand-alone query\n",
        "        with the given upcoming question\n",
        "        and the provided previous conversation\n",
        "        \"\"\"\n",
        "\n",
        "        docs = db._similarity_search_with_relevance_scores(stand_alone_query,k =3)\n",
        "        context = docs[0][0].page_content + \"\\n\" + docs[1][0].page_content + \"\\n\"+ docs[2][0].page_content\n",
        "        \"\"\"\n",
        "        Concatenates top 3 most relevant documents\n",
        "        to provide it as context for the bot to answer\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        relavance_scores = {\"doc1\":docs[0][1], \"doc2\":docs[1][1] , \"doc3\":docs[2][1]}\n",
        "\n",
        "        template = \"You need to behave as Sprinklr sales agent. You are currently doing the role of Sprinklr AI Assistant.  You should answer by referring context under triple backtiks-```\" + context + \"``` . If the question is not about Sprinklr, you must politely inform them that you are tuned to only answer questions about Sprinklr. \\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:\"\n",
        "        conversation.prompt.template = template\n",
        "        bot_message = conversation.predict(input=message)\n",
        "\n",
        "\n",
        "\n",
        "        if(len(conv) == 6):\n",
        "           conv.pop(0)\n",
        "           conv.pop(0)\n",
        "        \"\"\"\n",
        "        Populates the conversation history\n",
        "        with the current conversation\n",
        "        Had a window size of 3\n",
        "        \"\"\"\n",
        "        conv.append(f\"HumanMessage:{message}\\n\")\n",
        "        conv.append(f\"Sprinklr Bot Message:{bot_message}\\n\")\n",
        "\n",
        "        chat_history.append((message, bot_message))\n",
        "        return \"\", chat_history\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(share=True,debug=True)\n"
      ],
      "metadata": {
        "id": "0x1-F5Kf3Gj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}